{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter's Climate Tide\n",
    "## An Analysis of Tweets About Climate Change \n",
    "### By Arjun Gandhi\n",
    "### Last updated: December 12, 2020\n",
    "### CURRENTLY THIS IS A DRAFT, NOT THE FINAL SUBMISSION."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from wordcloud) (7.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from wordcloud) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.8/site-packages (from wordcloud) (1.19.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in /opt/conda/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /opt/conda/lib/python3.8/site-packages (from gensim) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: spacy in /opt/conda/lib/python3.8/site-packages (2.3.5)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (4.48.2)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.8/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy) (49.6.0.post20200814)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.8/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.8/site-packages (from spacy) (7.4.5)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.10)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already up-to-date: spacy-lookups-data in /opt/conda/lib/python3.8/site-packages (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy-lookups-data) (49.6.0.post20200814)\n",
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /opt/conda/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.8/site-packages (from en_core_web_sm==2.3.1) (2.3.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.48.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.6.0.post20200814)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.10)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!pip install -U spacy-lookups-data\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import datetime\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "I am starting off with a data set from Harvard that contains 39.6 million tweets related to climate change. The data set is in tweet IDs (numbers) so I need get the tweets for each tweet ID.\n",
    "\n",
    "Here is the link the data set: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/5QCCUU\n",
    "\n",
    "As states in the above link the data is from September 21, 2017 and May 17, 2019 and they had a gap in data collection from January 7, 2019 to April 17, 2019.\n",
    "\n",
    "To convert each tweet ID into the actual tweet data I am using this: Hydrator [Computer Software]. Retrieved from https://github.com/docnow/hydrator\n",
    "\n",
    "From the above repo, I downloaded this version of the app: https://github.com/DocNow/hydrator/releases/tag/v0.0.13\n",
    "\n",
    "The tweets are seperated by file (~ 10 million tweets/file). I made a Twitter account to connect my account this Hydrator. I then uploaded each txt file into Hydrator under \"Datasets\" in the desktop app. \n",
    "\n",
    "TALK ABOUT THEIR METHODOLOGY AND In your project talk about deletion of data when hydrated because tweets are unreachable for things like private accounts and deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>media</th>\n",
       "      <th>urls</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name.1</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_time_zone</th>\n",
       "      <th>user_urls</th>\n",
       "      <th>user_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Dec 11 01:00:00 +0000 2018</td>\n",
       "      <td>UN cdnpoli ONpoli ABpoli</td>\n",
       "      <td>https://twitter.com/TheRebelTV/status/10722948...</td>\n",
       "      <td>https://www.therebel.media/un-global-warming-m...</td>\n",
       "      <td>91</td>\n",
       "      <td>1072294898588631040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>205531</td>\n",
       "      <td>17484</td>\n",
       "      <td>1254</td>\n",
       "      <td>Canada and the world</td>\n",
       "      <td>Rebel News</td>\n",
       "      <td>RebelNewsOnline</td>\n",
       "      <td>39001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.rebelnews.com</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Jan 22 09:49:35 +0000 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>955376892026093569</td>\n",
       "      <td>Pontifex</td>\n",
       "      <td>9.551606e+17</td>\n",
       "      <td>500704345.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Frank</td>\n",
       "      <td>Frank34802901</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Sep 17 04:42:16 +0000 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://truthout.org/articles/national-park-of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1041547863795224576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2064</td>\n",
       "      <td>2383</td>\n",
       "      <td>98</td>\n",
       "      <td>USA</td>\n",
       "      <td>OurRevolution</td>\n",
       "      <td>LeftysUnite</td>\n",
       "      <td>50006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sat Aug 04 13:02:13 +0000 2018</td>\n",
       "      <td>Spain Portugal climatechange globalwarming Hea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://news.sky.com/story/live-scorching-satu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1025728615399469058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steven Hugh</td>\n",
       "      <td>Steven9Hugh</td>\n",
       "      <td>1402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://stevenhugh.wordpress.com/</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Nov 21 10:17:51 +0000 2017</td>\n",
       "      <td>Resist FakePresident Dontard GOP NRA War Clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/mattmfm/status/93272970237...</td>\n",
       "      <td>0</td>\n",
       "      <td>932915956824682496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6198</td>\n",
       "      <td>6731</td>\n",
       "      <td>121</td>\n",
       "      <td>the beautiful \"Jemez\" USA</td>\n",
       "      <td>Athoughtz</td>\n",
       "      <td>athoughtz</td>\n",
       "      <td>155949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://TokTok.com</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18323</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 16 06:51:55 +0000 2018</td>\n",
       "      <td>auspol solarenergy windpower Jobs environment ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.google.com.au/search?q=Morocco+and...</td>\n",
       "      <td>1</td>\n",
       "      <td>953157850536165376</td>\n",
       "      <td>JayWeatherill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350707926.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1288</td>\n",
       "      <td>500</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>Gareth_A bot I'm not</td>\n",
       "      <td>Gareth_PanChem</td>\n",
       "      <td>140364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18324</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sat Dec 30 13:58:31 +0000 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/MJ_Mouton/status/946959909...</td>\n",
       "      <td>0</td>\n",
       "      <td>947104617157992448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1977</td>\n",
       "      <td>1919</td>\n",
       "      <td>4</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>👍 S. Christy 😃</td>\n",
       "      <td>SChristy16</td>\n",
       "      <td>236234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18325</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sun Oct 22 05:13:47 +0000 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.asian-news-channel.tv/index.php/en/...</td>\n",
       "      <td>0</td>\n",
       "      <td>921967799781560322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1360</td>\n",
       "      <td>3206</td>\n",
       "      <td>7</td>\n",
       "      <td>New Delhi INDIA</td>\n",
       "      <td>Ramneet Kaur</td>\n",
       "      <td>RamneetANC</td>\n",
       "      <td>539851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.asian-news-chanel.tv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18326</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sun Sep 24 04:22:35 +0000 2017</td>\n",
       "      <td>ClimateChangeIsReal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>911808056693886977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>268</td>\n",
       "      <td>282</td>\n",
       "      <td>36</td>\n",
       "      <td>Chandigarh, Chandigarh India</td>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>amit219</td>\n",
       "      <td>25148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://amit219.blogspot.com</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18327</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wed Jan 17 20:01:05 +0000 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://notalotofpeopleknowthat.wordpress.com/...</td>\n",
       "      <td>2</td>\n",
       "      <td>953718838746546177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2782</td>\n",
       "      <td>2261</td>\n",
       "      <td>9</td>\n",
       "      <td>Wales &amp; England</td>\n",
       "      <td>Dr William Morgan #KBF</td>\n",
       "      <td>Bill963</td>\n",
       "      <td>7128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18328 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coordinates                      created_at  \\\n",
       "0             NaN  Tue Dec 11 01:00:00 +0000 2018   \n",
       "1             NaN  Mon Jan 22 09:49:35 +0000 2018   \n",
       "2             NaN  Mon Sep 17 04:42:16 +0000 2018   \n",
       "3             NaN  Sat Aug 04 13:02:13 +0000 2018   \n",
       "4             NaN  Tue Nov 21 10:17:51 +0000 2017   \n",
       "...           ...                             ...   \n",
       "18323         NaN  Tue Jan 16 06:51:55 +0000 2018   \n",
       "18324         NaN  Sat Dec 30 13:58:31 +0000 2017   \n",
       "18325         NaN  Sun Oct 22 05:13:47 +0000 2017   \n",
       "18326         NaN  Sun Sep 24 04:22:35 +0000 2017   \n",
       "18327         NaN  Wed Jan 17 20:01:05 +0000 2018   \n",
       "\n",
       "                                                hashtags  \\\n",
       "0                               UN cdnpoli ONpoli ABpoli   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3      Spain Portugal climatechange globalwarming Hea...   \n",
       "4      Resist FakePresident Dontard GOP NRA War Clima...   \n",
       "...                                                  ...   \n",
       "18323  auspol solarenergy windpower Jobs environment ...   \n",
       "18324                                                NaN   \n",
       "18325                                                NaN   \n",
       "18326                                ClimateChangeIsReal   \n",
       "18327                                                NaN   \n",
       "\n",
       "                                                   media  \\\n",
       "0      https://twitter.com/TheRebelTV/status/10722948...   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "18323                                                NaN   \n",
       "18324                                                NaN   \n",
       "18325                                                NaN   \n",
       "18326                                                NaN   \n",
       "18327                                                NaN   \n",
       "\n",
       "                                                    urls  favorite_count  \\\n",
       "0      https://www.therebel.media/un-global-warming-m...              91   \n",
       "1                                                    NaN               0   \n",
       "2      https://truthout.org/articles/national-park-of...               0   \n",
       "3      https://news.sky.com/story/live-scorching-satu...               1   \n",
       "4      https://twitter.com/mattmfm/status/93272970237...               0   \n",
       "...                                                  ...             ...   \n",
       "18323  https://www.google.com.au/search?q=Morocco+and...               1   \n",
       "18324  https://twitter.com/MJ_Mouton/status/946959909...               0   \n",
       "18325  http://www.asian-news-channel.tv/index.php/en/...               0   \n",
       "18326                                                NaN               0   \n",
       "18327  https://notalotofpeopleknowthat.wordpress.com/...               2   \n",
       "\n",
       "                        id in_reply_to_screen_name  in_reply_to_status_id  \\\n",
       "0      1072294898588631040                     NaN                    NaN   \n",
       "1       955376892026093569                Pontifex           9.551606e+17   \n",
       "2      1041547863795224576                     NaN                    NaN   \n",
       "3      1025728615399469058                     NaN                    NaN   \n",
       "4       932915956824682496                     NaN                    NaN   \n",
       "...                    ...                     ...                    ...   \n",
       "18323   953157850536165376           JayWeatherill                    NaN   \n",
       "18324   947104617157992448                     NaN                    NaN   \n",
       "18325   921967799781560322                     NaN                    NaN   \n",
       "18326   911808056693886977                     NaN                    NaN   \n",
       "18327   953718838746546177                     NaN                    NaN   \n",
       "\n",
       "       in_reply_to_user_id  ... user_followers_count user_friends_count  \\\n",
       "0                      NaN  ...               205531              17484   \n",
       "1              500704345.0  ...                    1                  4   \n",
       "2                      NaN  ...                 2064               2383   \n",
       "3                      NaN  ...                   25                 24   \n",
       "4                      NaN  ...                 6198               6731   \n",
       "...                    ...  ...                  ...                ...   \n",
       "18323          350707926.0  ...                 2035               1288   \n",
       "18324                  NaN  ...                 1977               1919   \n",
       "18325                  NaN  ...                 1360               3206   \n",
       "18326                  NaN  ...                  268                282   \n",
       "18327                  NaN  ...                 2782               2261   \n",
       "\n",
       "      user_listed_count                 user_location               user_name  \\\n",
       "0                  1254          Canada and the world              Rebel News   \n",
       "1                     0                 United States                   Frank   \n",
       "2                    98                           USA           OurRevolution   \n",
       "3                     1                           NaN             Steven Hugh   \n",
       "4                   121     the beautiful \"Jemez\" USA               Athoughtz   \n",
       "...                 ...                           ...                     ...   \n",
       "18323               500               South Australia    Gareth_A bot I'm not   \n",
       "18324                 4           Southern California          👍 S. Christy 😃   \n",
       "18325                 7               New Delhi INDIA            Ramneet Kaur   \n",
       "18326                36  Chandigarh, Chandigarh India             Amit Sharma   \n",
       "18327                 9               Wales & England  Dr William Morgan #KBF   \n",
       "\n",
       "       user_screen_name.1 user_statuses_count user_time_zone  \\\n",
       "0         RebelNewsOnline               39001            NaN   \n",
       "1           Frank34802901                 100            NaN   \n",
       "2             LeftysUnite               50006            NaN   \n",
       "3             Steven9Hugh                1402            NaN   \n",
       "4               athoughtz              155949            NaN   \n",
       "...                   ...                 ...            ...   \n",
       "18323      Gareth_PanChem              140364            NaN   \n",
       "18324          SChristy16              236234            NaN   \n",
       "18325          RamneetANC              539851            NaN   \n",
       "18326             amit219               25148            NaN   \n",
       "18327             Bill963                7128            NaN   \n",
       "\n",
       "                               user_urls user_verified  \n",
       "0              https://www.rebelnews.com          True  \n",
       "1                                    NaN         False  \n",
       "2                                    NaN         False  \n",
       "3      https://stevenhugh.wordpress.com/         False  \n",
       "4                      http://TokTok.com         False  \n",
       "...                                  ...           ...  \n",
       "18323                                NaN         False  \n",
       "18324                                NaN         False  \n",
       "18325    http://www.asian-news-chanel.tv         False  \n",
       "18326        http://amit219.blogspot.com         False  \n",
       "18327                                NaN         False  \n",
       "\n",
       "[18328 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/tweets_25K.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "The data set has lots of data that is not needed for this analysis. Since we are looking at sentiment over time and other factors related to polticis of a state and events, it is simplest to just drop all non-English tweets.\n",
    "\n",
    "There are lots of extranenous columns that are not relavent to this project so I just dropped them. These included geolocation data that was often missing, user information, and extranenous data about a tweet like time zone and lanague (since I drop all non-English ones to begin). These include things like user specifics like their profile details and other things like the URL of thr tweet or the language since all will be English. \n",
    "\n",
    "I then renamed some columns for my ease of use of the data set and switched the tweet ID to be the index columns.\n",
    "\n",
    "The date and time is given as a string so I use regular expressions to convert that to a date time object. The hashtag column is given as one string so I split that into a list of hastags.\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date/time</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweeter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1072294898588631040</th>\n",
       "      <td>Tue Dec 11 01:00:00 +0000 2018</td>\n",
       "      <td>91</td>\n",
       "      <td>55</td>\n",
       "      <td>.@TheRebelTV goes to two different #UN confere...</td>\n",
       "      <td>RebelNewsOnline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955376892026093569</th>\n",
       "      <td>Mon Jan 22 09:49:35 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@Pontifex Prayers  to God the one &amp;amp; only t...</td>\n",
       "      <td>Frank34802901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025728615399469058</th>\n",
       "      <td>Sat Aug 04 13:02:13 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Red alert in #Spain and #Portugal as Europe ne...</td>\n",
       "      <td>Steven9Hugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932915956824682496</th>\n",
       "      <td>Tue Nov 21 10:17:51 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Trump /GOP are the swamp #Resist #FakePresiden...</td>\n",
       "      <td>athoughtz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041547806622797824</th>\n",
       "      <td>Mon Sep 17 04:42:02 +0000 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Study: Green Buildings Save $6.7 Billion in #H...</td>\n",
       "      <td>IndiaGreenBldg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016831500015136768</th>\n",
       "      <td>Tue Jul 10 23:48:16 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>#PLOSMedicine: #ClimateChange &amp;amp; #WomensHea...</td>\n",
       "      <td>HEARDatUNSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953157850536165376</th>\n",
       "      <td>Tue Jan 16 06:51:55 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@JayWeatherill #auspol. PHOTOVOLTAIC #solarene...</td>\n",
       "      <td>Gareth_PanChem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921967799781560322</th>\n",
       "      <td>Sun Oct 22 05:13:47 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EPA’s climate website removes resources to fig...</td>\n",
       "      <td>RamneetANC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911808056693886977</th>\n",
       "      <td>Sun Sep 24 04:22:35 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There used to be days when it kept on raining ...</td>\n",
       "      <td>amit219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953718838746546177</th>\n",
       "      <td>Wed Jan 17 20:01:05 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Global temperature data for the last 12 months...</td>\n",
       "      <td>Bill963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16815 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date/time  favorite_count  \\\n",
       "tweetID                                                               \n",
       "1072294898588631040  Tue Dec 11 01:00:00 +0000 2018              91   \n",
       "955376892026093569   Mon Jan 22 09:49:35 +0000 2018               0   \n",
       "1025728615399469058  Sat Aug 04 13:02:13 +0000 2018               1   \n",
       "932915956824682496   Tue Nov 21 10:17:51 +0000 2017               0   \n",
       "1041547806622797824  Mon Sep 17 04:42:02 +0000 2018               3   \n",
       "...                                             ...             ...   \n",
       "1016831500015136768  Tue Jul 10 23:48:16 +0000 2018               2   \n",
       "953157850536165376   Tue Jan 16 06:51:55 +0000 2018               1   \n",
       "921967799781560322   Sun Oct 22 05:13:47 +0000 2017               0   \n",
       "911808056693886977   Sun Sep 24 04:22:35 +0000 2017               0   \n",
       "953718838746546177   Wed Jan 17 20:01:05 +0000 2018               2   \n",
       "\n",
       "                     retweet_count  \\\n",
       "tweetID                              \n",
       "1072294898588631040             55   \n",
       "955376892026093569               0   \n",
       "1025728615399469058              0   \n",
       "932915956824682496               0   \n",
       "1041547806622797824              1   \n",
       "...                            ...   \n",
       "1016831500015136768              0   \n",
       "953157850536165376               0   \n",
       "921967799781560322               0   \n",
       "911808056693886977               0   \n",
       "953718838746546177               1   \n",
       "\n",
       "                                                                  text  \\\n",
       "tweetID                                                                  \n",
       "1072294898588631040  .@TheRebelTV goes to two different #UN confere...   \n",
       "955376892026093569   @Pontifex Prayers  to God the one &amp; only t...   \n",
       "1025728615399469058  Red alert in #Spain and #Portugal as Europe ne...   \n",
       "932915956824682496   Trump /GOP are the swamp #Resist #FakePresiden...   \n",
       "1041547806622797824  Study: Green Buildings Save $6.7 Billion in #H...   \n",
       "...                                                                ...   \n",
       "1016831500015136768  #PLOSMedicine: #ClimateChange &amp; #WomensHea...   \n",
       "953157850536165376   @JayWeatherill #auspol. PHOTOVOLTAIC #solarene...   \n",
       "921967799781560322   EPA’s climate website removes resources to fig...   \n",
       "911808056693886977   There used to be days when it kept on raining ...   \n",
       "953718838746546177   Global temperature data for the last 12 months...   \n",
       "\n",
       "                             tweeter  \n",
       "tweetID                               \n",
       "1072294898588631040  RebelNewsOnline  \n",
       "955376892026093569     Frank34802901  \n",
       "1025728615399469058      Steven9Hugh  \n",
       "932915956824682496         athoughtz  \n",
       "1041547806622797824   IndiaGreenBldg  \n",
       "...                              ...  \n",
       "1016831500015136768      HEARDatUNSW  \n",
       "953157850536165376    Gareth_PanChem  \n",
       "921967799781560322        RamneetANC  \n",
       "911808056693886977           amit219  \n",
       "953718838746546177           Bill963  \n",
       "\n",
       "[16815 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove non-English tweets from the data set\n",
    "data = data[data[\"lang\"] == \"en\"]\n",
    "\n",
    "# Drop all the unneeded columns from the data set\n",
    "cols_to_delete = [\"user_urls\", \"user_statuses_count\", \"coordinates\", \"user_name\", \"in_reply_to_status_id\", \n",
    "                  \"in_reply_to_user_id\", \"user_time_zone\", \"urls\", \"lang\", \"media\", \"source\", \n",
    "                  \"retweet_screen_name\", \"retweet_id\", \"possibly_sensitive\", \"tweet_url\",\n",
    "                  \"user_default_profile_image\", \"user_friends_count\", \"user_verified\", \"user_location\", \n",
    "                   \"in_reply_to_screen_name\", \"user_screen_name.1\",\n",
    "                  \"user_favourites_count\", \"user_listed_count\", \"user_created_at\", \"user_description\", \"place\", \n",
    "                 \"user_followers_count\", \"hashtags\"]\n",
    "\n",
    "data = data.drop(columns=cols_to_delete)\n",
    "\n",
    "# Swap the index column from 0...n to the tweet ID and rename the column from id to tweetID and rename to clarify\n",
    "# column meaning\n",
    "data = data.rename(columns={\"id\": \"tweetID\", \"created_at\": \"date/time\", \"user_screen_name\": \"tweeter\"})\n",
    "data = data.set_index('tweetID')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date/time</th>\n",
       "      <th>text</th>\n",
       "      <th>tweeter</th>\n",
       "      <th>total_interactions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1072294898588631040</th>\n",
       "      <td>Tue Dec 11 01:00:00 +0000 2018</td>\n",
       "      <td>.@TheRebelTV goes to two different #UN confere...</td>\n",
       "      <td>RebelNewsOnline</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955376892026093569</th>\n",
       "      <td>Mon Jan 22 09:49:35 +0000 2018</td>\n",
       "      <td>@Pontifex Prayers  to God the one &amp;amp; only t...</td>\n",
       "      <td>Frank34802901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025728615399469058</th>\n",
       "      <td>Sat Aug 04 13:02:13 +0000 2018</td>\n",
       "      <td>Red alert in #Spain and #Portugal as Europe ne...</td>\n",
       "      <td>Steven9Hugh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932915956824682496</th>\n",
       "      <td>Tue Nov 21 10:17:51 +0000 2017</td>\n",
       "      <td>Trump /GOP are the swamp #Resist #FakePresiden...</td>\n",
       "      <td>athoughtz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041547806622797824</th>\n",
       "      <td>Mon Sep 17 04:42:02 +0000 2018</td>\n",
       "      <td>Study: Green Buildings Save $6.7 Billion in #H...</td>\n",
       "      <td>IndiaGreenBldg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016831500015136768</th>\n",
       "      <td>Tue Jul 10 23:48:16 +0000 2018</td>\n",
       "      <td>#PLOSMedicine: #ClimateChange &amp;amp; #WomensHea...</td>\n",
       "      <td>HEARDatUNSW</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953157850536165376</th>\n",
       "      <td>Tue Jan 16 06:51:55 +0000 2018</td>\n",
       "      <td>@JayWeatherill #auspol. PHOTOVOLTAIC #solarene...</td>\n",
       "      <td>Gareth_PanChem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921967799781560322</th>\n",
       "      <td>Sun Oct 22 05:13:47 +0000 2017</td>\n",
       "      <td>EPA’s climate website removes resources to fig...</td>\n",
       "      <td>RamneetANC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911808056693886977</th>\n",
       "      <td>Sun Sep 24 04:22:35 +0000 2017</td>\n",
       "      <td>There used to be days when it kept on raining ...</td>\n",
       "      <td>amit219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953718838746546177</th>\n",
       "      <td>Wed Jan 17 20:01:05 +0000 2018</td>\n",
       "      <td>Global temperature data for the last 12 months...</td>\n",
       "      <td>Bill963</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16815 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date/time  \\\n",
       "tweetID                                               \n",
       "1072294898588631040  Tue Dec 11 01:00:00 +0000 2018   \n",
       "955376892026093569   Mon Jan 22 09:49:35 +0000 2018   \n",
       "1025728615399469058  Sat Aug 04 13:02:13 +0000 2018   \n",
       "932915956824682496   Tue Nov 21 10:17:51 +0000 2017   \n",
       "1041547806622797824  Mon Sep 17 04:42:02 +0000 2018   \n",
       "...                                             ...   \n",
       "1016831500015136768  Tue Jul 10 23:48:16 +0000 2018   \n",
       "953157850536165376   Tue Jan 16 06:51:55 +0000 2018   \n",
       "921967799781560322   Sun Oct 22 05:13:47 +0000 2017   \n",
       "911808056693886977   Sun Sep 24 04:22:35 +0000 2017   \n",
       "953718838746546177   Wed Jan 17 20:01:05 +0000 2018   \n",
       "\n",
       "                                                                  text  \\\n",
       "tweetID                                                                  \n",
       "1072294898588631040  .@TheRebelTV goes to two different #UN confere...   \n",
       "955376892026093569   @Pontifex Prayers  to God the one &amp; only t...   \n",
       "1025728615399469058  Red alert in #Spain and #Portugal as Europe ne...   \n",
       "932915956824682496   Trump /GOP are the swamp #Resist #FakePresiden...   \n",
       "1041547806622797824  Study: Green Buildings Save $6.7 Billion in #H...   \n",
       "...                                                                ...   \n",
       "1016831500015136768  #PLOSMedicine: #ClimateChange &amp; #WomensHea...   \n",
       "953157850536165376   @JayWeatherill #auspol. PHOTOVOLTAIC #solarene...   \n",
       "921967799781560322   EPA’s climate website removes resources to fig...   \n",
       "911808056693886977   There used to be days when it kept on raining ...   \n",
       "953718838746546177   Global temperature data for the last 12 months...   \n",
       "\n",
       "                             tweeter  total_interactions  \n",
       "tweetID                                                   \n",
       "1072294898588631040  RebelNewsOnline                 146  \n",
       "955376892026093569     Frank34802901                   0  \n",
       "1025728615399469058      Steven9Hugh                   1  \n",
       "932915956824682496         athoughtz                   0  \n",
       "1041547806622797824   IndiaGreenBldg                   4  \n",
       "...                              ...                 ...  \n",
       "1016831500015136768      HEARDatUNSW                   2  \n",
       "953157850536165376    Gareth_PanChem                   1  \n",
       "921967799781560322        RamneetANC                   0  \n",
       "911808056693886977           amit219                   0  \n",
       "953718838746546177           Bill963                   3  \n",
       "\n",
       "[16815 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the number of favorites and retweets for a tweet into an total interactions score\n",
    "total_interactions = []\n",
    "\n",
    "for row in data.iterrows():\n",
    "    tweet = row[1] \n",
    "    total = tweet[\"retweet_count\"] + tweet[\"favorite_count\"]\n",
    "    total_interactions.append(total)\n",
    "\n",
    "# Swap out the current RT and favorites columns for the total interactions columns\n",
    "data[\"total_interactions\"] = total_interactions\n",
    "data = data.drop(columns=[\"retweet_count\", \"favorite_count\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweeter</th>\n",
       "      <th>total_interactions</th>\n",
       "      <th>date_tweeted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1072294898588631040</th>\n",
       "      <td>.@TheRebelTV goes to two different #UN confere...</td>\n",
       "      <td>RebelNewsOnline</td>\n",
       "      <td>146</td>\n",
       "      <td>2018-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955376892026093569</th>\n",
       "      <td>@Pontifex Prayers  to God the one &amp;amp; only t...</td>\n",
       "      <td>Frank34802901</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025728615399469058</th>\n",
       "      <td>Red alert in #Spain and #Portugal as Europe ne...</td>\n",
       "      <td>Steven9Hugh</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932915956824682496</th>\n",
       "      <td>Trump /GOP are the swamp #Resist #FakePresiden...</td>\n",
       "      <td>athoughtz</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041547806622797824</th>\n",
       "      <td>Study: Green Buildings Save $6.7 Billion in #H...</td>\n",
       "      <td>IndiaGreenBldg</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016831500015136768</th>\n",
       "      <td>#PLOSMedicine: #ClimateChange &amp;amp; #WomensHea...</td>\n",
       "      <td>HEARDatUNSW</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953157850536165376</th>\n",
       "      <td>@JayWeatherill #auspol. PHOTOVOLTAIC #solarene...</td>\n",
       "      <td>Gareth_PanChem</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921967799781560322</th>\n",
       "      <td>EPA’s climate website removes resources to fig...</td>\n",
       "      <td>RamneetANC</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911808056693886977</th>\n",
       "      <td>There used to be days when it kept on raining ...</td>\n",
       "      <td>amit219</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953718838746546177</th>\n",
       "      <td>Global temperature data for the last 12 months...</td>\n",
       "      <td>Bill963</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16815 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "tweetID                                                                  \n",
       "1072294898588631040  .@TheRebelTV goes to two different #UN confere...   \n",
       "955376892026093569   @Pontifex Prayers  to God the one &amp; only t...   \n",
       "1025728615399469058  Red alert in #Spain and #Portugal as Europe ne...   \n",
       "932915956824682496   Trump /GOP are the swamp #Resist #FakePresiden...   \n",
       "1041547806622797824  Study: Green Buildings Save $6.7 Billion in #H...   \n",
       "...                                                                ...   \n",
       "1016831500015136768  #PLOSMedicine: #ClimateChange &amp; #WomensHea...   \n",
       "953157850536165376   @JayWeatherill #auspol. PHOTOVOLTAIC #solarene...   \n",
       "921967799781560322   EPA’s climate website removes resources to fig...   \n",
       "911808056693886977   There used to be days when it kept on raining ...   \n",
       "953718838746546177   Global temperature data for the last 12 months...   \n",
       "\n",
       "                             tweeter  total_interactions date_tweeted  \n",
       "tweetID                                                                \n",
       "1072294898588631040  RebelNewsOnline                 146   2018-12-11  \n",
       "955376892026093569     Frank34802901                   0   2018-01-22  \n",
       "1025728615399469058      Steven9Hugh                   1   2018-08-04  \n",
       "932915956824682496         athoughtz                   0   2017-11-21  \n",
       "1041547806622797824   IndiaGreenBldg                   4   2018-09-17  \n",
       "...                              ...                 ...          ...  \n",
       "1016831500015136768      HEARDatUNSW                   2   2018-07-10  \n",
       "953157850536165376    Gareth_PanChem                   1   2018-01-16  \n",
       "921967799781560322        RamneetANC                   0   2017-10-22  \n",
       "911808056693886977           amit219                   0   2017-09-24  \n",
       "953718838746546177           Bill963                   3   2018-01-17  \n",
       "\n",
       "[16815 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dates time strings into datetime objects\n",
    "dates = []\n",
    "\n",
    "# Matching this text\n",
    "# Mon Jan 22 09:49:35 +0000 2018\n",
    "# For every row in the dataframe\n",
    "regex = re.compile(r\"(\\w{3}) (\\w{3}) (\\d\\d) (\\d\\d:\\d\\d:\\d\\d) \\+(0{4}) (\\d{4})\")\n",
    "\n",
    "# Given a string of a month return the corresponding integer for that month i.e. Jan == 1\n",
    "def numerize(str):\n",
    "    month = str.lower()\n",
    "    if (month == \"jan\"): return 1\n",
    "    elif (month == \"feb\"): return 2\n",
    "    elif (month == \"mar\"): return 3\n",
    "    elif (month == \"apr\"): return 4\n",
    "    elif (month == \"may\"): return 5\n",
    "    elif (month == \"jun\"): return 6\n",
    "    elif (month == \"jul\"): return 7 \n",
    "    elif (month == \"aug\"): return 8\n",
    "    elif (month == \"sep\"): return 9\n",
    "    elif (month == \"oct\"): return 10\n",
    "    elif (month == \"nov\"): return 11\n",
    "    elif (month == \"dec\"): return 12\n",
    "        \n",
    "for row in data.iterrows():\n",
    "    dt = row[1][\"date/time\"]\n",
    "    matches = re.search(regex, dt)\n",
    "    groups = matches.groups()    \n",
    "    month = numerize(groups[1])\n",
    "    d = datetime.date(int(groups[5]), month, int(groups[2]))\n",
    "    dates.append(d)\n",
    "    \n",
    "data = data.drop(columns=[\"date/time\"])\n",
    "data[\"date_tweeted\"] = dates\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the tweets for sentiment analysis\n",
    "There are several things that need to be done to the actual text of the tweets before we can do sentiment analysis on them. To starts of, I will do some basic things like make all tweet bodies lower case so that words like CLIMATE and climate and cLiMate are all treated the same by the model I use later on. Next, I am going to remove all links from these tweets because that is irrelvanet to the sentiment of the tweet. There are many things like this that I will do here then I will move on to make the tweets \"linguistically sound\" for analysis by doing things like removing words without meaning that won't contribute the analysis and then making all words their base word or lemmatizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweeter</th>\n",
       "      <th>total_interactions</th>\n",
       "      <th>date_tweeted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1072294898588631040</th>\n",
       "      <td>.@TheRebelTV goes to two different #UN confere...</td>\n",
       "      <td>RebelNewsOnline</td>\n",
       "      <td>146</td>\n",
       "      <td>2018-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955376892026093569</th>\n",
       "      <td>@Pontifex Prayers  to God the one &amp;amp; only t...</td>\n",
       "      <td>Frank34802901</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025728615399469058</th>\n",
       "      <td>Red alert in #Spain and #Portugal as Europe ne...</td>\n",
       "      <td>Steven9Hugh</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932915956824682496</th>\n",
       "      <td>Trump /GOP are the swamp #Resist #FakePresiden...</td>\n",
       "      <td>athoughtz</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041547806622797824</th>\n",
       "      <td>Study: Green Buildings Save $6.7 Billion in #H...</td>\n",
       "      <td>IndiaGreenBldg</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016831500015136768</th>\n",
       "      <td>#PLOSMedicine: #ClimateChange &amp;amp; #WomensHea...</td>\n",
       "      <td>HEARDatUNSW</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953157850536165376</th>\n",
       "      <td>@JayWeatherill #auspol. PHOTOVOLTAIC #solarene...</td>\n",
       "      <td>Gareth_PanChem</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921967799781560322</th>\n",
       "      <td>EPA’s climate website removes resources to fig...</td>\n",
       "      <td>RamneetANC</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911808056693886977</th>\n",
       "      <td>There used to be days when it kept on raining ...</td>\n",
       "      <td>amit219</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953718838746546177</th>\n",
       "      <td>Global temperature data for the last 12 months...</td>\n",
       "      <td>Bill963</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16815 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "tweetID                                                                  \n",
       "1072294898588631040  .@TheRebelTV goes to two different #UN confere...   \n",
       "955376892026093569   @Pontifex Prayers  to God the one &amp; only t...   \n",
       "1025728615399469058  Red alert in #Spain and #Portugal as Europe ne...   \n",
       "932915956824682496   Trump /GOP are the swamp #Resist #FakePresiden...   \n",
       "1041547806622797824  Study: Green Buildings Save $6.7 Billion in #H...   \n",
       "...                                                                ...   \n",
       "1016831500015136768  #PLOSMedicine: #ClimateChange &amp; #WomensHea...   \n",
       "953157850536165376   @JayWeatherill #auspol. PHOTOVOLTAIC #solarene...   \n",
       "921967799781560322   EPA’s climate website removes resources to fig...   \n",
       "911808056693886977   There used to be days when it kept on raining ...   \n",
       "953718838746546177   Global temperature data for the last 12 months...   \n",
       "\n",
       "                             tweeter  total_interactions date_tweeted  \n",
       "tweetID                                                                \n",
       "1072294898588631040  RebelNewsOnline                 146   2018-12-11  \n",
       "955376892026093569     Frank34802901                   0   2018-01-22  \n",
       "1025728615399469058      Steven9Hugh                   1   2018-08-04  \n",
       "932915956824682496         athoughtz                   0   2017-11-21  \n",
       "1041547806622797824   IndiaGreenBldg                   4   2018-09-17  \n",
       "...                              ...                 ...          ...  \n",
       "1016831500015136768      HEARDatUNSW                   2   2018-07-10  \n",
       "953157850536165376    Gareth_PanChem                   1   2018-01-16  \n",
       "921967799781560322        RamneetANC                   0   2017-10-22  \n",
       "911808056693886977           amit219                   0   2017-09-24  \n",
       "953718838746546177           Bill963                   3   2018-01-17  \n",
       "\n",
       "[16815 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkless = []\n",
    "regex = re.compile(r\"http\\S+\")\n",
    "\n",
    "# remove all links from each tweet\n",
    "for row in data.iterrows():\n",
    "    txt = row[1][\"text\"]\n",
    "    if txt.find(\"https://t.co\"): \n",
    "        ll = re.sub(regex, \"\", txt)\n",
    "        linkless.append(ll)\n",
    "    else: \n",
    "        linkless.append(txt)\n",
    "\n",
    "data[\"text\"] = linkless\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Clean up\" the tweets for analysis\n",
    "I will be using GenSim to do much of the natural langauge processing in this project. \"Convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for r in data.iterrows():\n",
    "    tweets.append(gensim.utils.simple_preprocess(r[1][\"text\"]))\n",
    "    \n",
    "data[\"tokens\"] = tweets \n",
    "data = data.drop(columns=[\"text\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords and Lemmatization \n",
    "Here I will remove stopwards from the tweet bodies. These are words like \"I\" and \"this\" that add little meaning to the tweet but if left in the text will give me an innacurate depiction of the most common words in the tweets. Thne I will perform lemmatization on the tweets. This just means taking words that linguisticlly mean the same thing like walker and walking and reducing them to their base. In this case the word walk. You can read more here: https://en.wikipedia.org/wiki/Lemmatisation. I will be doing this uisng spaCy (https://spacy.io).\n",
    "\n",
    "You can find installation instructions for spaCy here: https://spacy.io/usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model \n",
    "model = spacy.load('en_core_web_sm')\n",
    "\n",
    "lemmatized = []\n",
    "# Lemmatization of tweets and stopwords removal\n",
    "for r in data.iterrows():\n",
    "    # In order to lemmatize we need to get the tweet as a string not a str list so take cleaned \n",
    "    # tokens and concat them\n",
    "    tweet = r[1][\"tokens\"]\n",
    "    text = \" \".join(tweet)\n",
    "    lemmatized.append([tok.lemma_ for tok in list(model(text)) if (tok.is_stop==False)])\n",
    "    \n",
    "data[\"tokens\"] = lemmatized\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the tweets that are one string per tweet for use later\n",
    "data[\"tweet\"]=data[\"tokens\"].apply(lambda lst: \" \".join(lst))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to split the data frame up by year so I can visualize different time periods\n",
    "data = data.sort_values(by=[\"date_tweeted\"])\n",
    "\n",
    "# To make splitting up the data frame up by time easier, I will a year column to the tweet\n",
    "years = []\n",
    "for r in data.iterrows():\n",
    "    years.append(r[1][\"date_tweeted\"].year)\n",
    "    \n",
    "data[\"year\"] = years\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using wordcloud to visualize the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bag of words\n",
    "cv=CountVectorizer(analyzer='word')\n",
    "\n",
    "def make_bag_of_words(tweets):\n",
    "    info = cv.fit_transform(tweets[\"tweet\"])\n",
    "    bow = pd.DataFrame(info.toarray(), columns=cv.get_feature_names())\n",
    "    bow.index=tweets.index\n",
    "    return bow\n",
    "\n",
    "bags = []\n",
    "for i in range(2017,2020):\n",
    "    bags.append(make_bag_of_words(data[data[\"year\"] == i]))\n",
    "    \n",
    "# example output for 2019\n",
    "bags[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the bag of words's take a sum over all the rows i.e. create a series that has time each word is used\n",
    "# over all tweets and make a word cloud for each year\n",
    "for i in range(3):\n",
    "    sums = bags[i].sum()\n",
    "    wc = WordCloud(width=800, height=600, max_words=40,colormap=\"Dark2\").generate_from_frequencies(et)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a word cloud of the 500 most interacted with tweets.\n",
    "Here I will use the WordCloud library to visualize the 500 most interacted with tweets. I define an interaction as a favorite or retweet and I weighted them equally when I combined the two earlier.\n",
    "\n",
    "To make this word cloud I referenced this website: https://www.datacamp.com/community/tutorials/wordcloud-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a word count of the most interacted with tweets (what got the most likes and retweets)\n",
    "data = data.sort_values(by=[\"total_interactions\"], ascending=False)\n",
    "top_100 = data.head(500)\n",
    "text = ''.join(map(str, top_100[\"tokens\"]))\n",
    "wordcloud = WordCloud(background_color=\"white\").generate(text)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there times where people tweet about climate change more than others?\n",
    "# To make things simple lets look at the number of tweets per month year pair in the dataset\n",
    "tweets_per_month = {}\n",
    "\n",
    "# As you may recall data was collected from September 21, 2017 and May 17, 2019 and they had a gap in \n",
    "# data collection from January 7, 2019 to April 17, 2019.\n",
    "\n",
    "# Initalize the value for a tuple key for the month/year pair to 0 for all months where data was collected\n",
    "# 2017\n",
    "for i in [9, 10, 11, 12]:\n",
    "    tweets_per_month[(i,2017)] = 0\n",
    "\n",
    "# 2018\n",
    "for i in range(1,13):\n",
    "    tweets_per_month[(i,2018)] = 0\n",
    "    \n",
    "# 2019\n",
    "for i in [1, 4, 5]: \n",
    "    tweets_per_month[(i,2019)] = 0\n",
    "    \n",
    "# Iterate over data frame and add one to each tweet's proper month/year tuple's value\n",
    "for r in data.iterrows():\n",
    "    row = r[1]\n",
    "    date = row[\"date_tweeted\"]\n",
    "    tweets_per_month[(date.month, date.year)] += 1\n",
    "    \n",
    "# Remove Septembr 2017 and January-April 2019 because most during most the month data was not collected\n",
    "tweets_per_month.pop((9, 2017))\n",
    "tweets_per_month.pop((1, 2019))\n",
    "tweets_per_month.pop((2, 2019))\n",
    "tweets_per_month.pop((3, 2019))\n",
    "tweets_per_month.pop((4, 2019))\n",
    "\n",
    "# I decided to also drop May 2019 from this visualization because if I leave it then there is a 5 month gap in\n",
    "# data and this is not reflected in the plot.\n",
    "tweets_per_month.pop((5, 2019))\n",
    "\n",
    "tweets_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tuples to strings\n",
    "time = list(tweets_per_month.keys())\n",
    "count = list(tweets_per_month.values())\n",
    "\n",
    "dates = []\n",
    "for t in time:\n",
    "    dates.append(str(t[0]) + \"/\" + str(t[1])[-2:])\n",
    "    \n",
    "df = pd.DataFrame(columns = ['date', 'tweet_count'])\n",
    "df['date'] = dates\n",
    "\n",
    "df['tweet_count'] = count\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(dates,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet_length']=data['clean_and_tokenized'].apply(lambda tokens: len(tokens))\n",
    "sns.barplot(x='year',y='tweet_length',data=data).set(title=\"Approximate Length of Tweet by Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the length of the Tweet that we are looking at here is approximate because we removed things like links (which are notably not words) and GenSim's preprocess() function removes very short and long words from the tweets to help me get the most semantically meanigful words from the tweets.\n",
    "\n",
    "When looking at this graph one major thing to consider is that it may not be such a simple oh tweet length about climate must be going up year after year for a couple of reasons. One major factor is the sample from 2018 is much larger than the other two because the majority of data colleciton took place in 2018 and much of Jan-Apr 2019 lacked sampling. In 2019, GWU collected data the first week of January, not at all in Feb-Mar, the last two weeks of April, and most of May.\n",
    "\n",
    "So roughly speaking we can say that tweet length may have increased when talking about tweets related to climate change but because of what I just said this is at best a rough guess because we aren't really saying massive changes in length for example between 2018 and 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDK IF THIS WORKS BECAUSE THIS RUNS SO SLOW\n",
    "# Who tweets about climate the most?\n",
    "tweeters = list(set(data[\"tweeter\"]))\n",
    "times_tweeted = dict.fromkeys(tweeters , 0)\n",
    "\n",
    "# Calculate how many times each tweeter has tweeted\n",
    "for r in data.iterrows():\n",
    "    row = r[1]\n",
    "    user = row[\"tweeter\"]\n",
    "    times_tweeted[user] += 1\n",
    "    \n",
    "users = list(times_tweeted.keys())\n",
    "counts = list(times_tweeted.values())\n",
    "\n",
    "df = pd.DataFrame(columns = ['user', 'tweet count'])\n",
    "df[\"user\"] = users\n",
    "df[\"tweet count\"] = counts\n",
    "sns.barplot(x='user',y=\"tweet count\",data=df).set(title=\"Times Tweeted per User\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
